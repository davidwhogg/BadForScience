{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjJiTgGFZ6E44ER5VrWKnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidwhogg/BadForScience/blob/main/notebooks/bias_in_regression_outputs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biases in regression outputs\n",
        "The goal of this notebook is to show that when the data have small information about the label, then population-level inferences using the output labels are biased.\n",
        "\n",
        "## Author:\n",
        "- **David W Hogg** (NYU) (MPIA) (Flatiron)\n",
        "\n",
        "## License:\n",
        "Copyright 2023, 2024 the author. All code is released open-source under the MIT License.\n",
        "\n",
        "## To-do:\n",
        "- Make plots that are publication-worthy.\n",
        "- Play with hyper-parameters of the MLP and the data generation to see how the results depend on choices."
      ],
      "metadata": {
        "id": "YExxpbJOvPmQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Aqw-KrMwdmB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "rng = np.random.default_rng(17)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set hyper-parameters\n",
        "M = 110 # dimension of the data (thinking XP spectra)\n",
        "K = 13 # number of latent (unknown) parameters beyond age and guiding radius\n",
        "N_train = 2 ** 12\n",
        "N_valid = 2 ** 11\n",
        "N_extra = 2 ** 17\n",
        "N_total = N_train + N_valid + N_extra\n",
        "maxR = 14.0 # kpc\n",
        "maxage = 13.0 # Gyr\n",
        "agerange = 3.0 # Gyr\n",
        "agefactor = 0.08 # make this smaller to reduce age information in the data set\n",
        "datanoise = 0.05 # noise level for the data\n",
        "agenoise = 1.0 # Gyr age label noise level\n",
        "print(N_train, N_valid, N_total, maxR)"
      ],
      "metadata": {
        "id": "kFXEzCjbw7Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make latent true ages and other properties\n",
        "true_guide_radii = rng.uniform(0., maxR, size=N_total)\n",
        "true_ages = maxage - (maxage / maxR) * true_guide_radii + agerange * rng.normal(size=N_total)\n",
        "okay = (true_ages > 0.) * (true_ages < maxage)\n",
        "true_guide_radii = true_guide_radii[okay]\n",
        "true_ages = true_ages[okay]\n",
        "N_total = len(true_ages)\n",
        "N_test = N_total - N_train - N_valid\n",
        "true_latents = np.random.normal(size=(N_total, K))\n",
        "print(true_guide_radii.shape, true_ages.shape, true_latents.shape)"
      ],
      "metadata": {
        "id": "N9bqwuxgwpr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make true data\n",
        "radius_vec = np.random.normal(size=M)\n",
        "age_vec = agefactor * np.random.normal(size=M)\n",
        "latent_vecs = np.random.normal(size=(K, M))\n",
        "true_data = (true_ages[:, None] * age_vec[None, :]\n",
        "            + true_latents @ latent_vecs) / np.sqrt(K + 1)\n",
        "true_data = 1. + np.clip(true_data, -1.0, 0.0) # apply RELU-like nonlinearity\n",
        "print(true_data.shape)"
      ],
      "metadata": {
        "id": "HCN3vnKkySzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add noise to the data and labels\n",
        "data = true_data + datanoise * rng.normal(size=true_data.shape)\n",
        "ages = true_ages + agenoise * rng.normal(size=true_ages.shape)\n",
        "print(data.shape, ages.shape)"
      ],
      "metadata": {
        "id": "H76FQ0ULzvcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"data examples (vertically offset)\")\n",
        "for i in range(10):\n",
        "    plt.plot(data[i] + 1.2 * i, \"k-\")\n",
        "    plt.text(M, 1.2 * i + 0.5, \"{:4.1f}\".format(ages[i]))\n",
        "plt.xlim(-0.5, M - 0.5)"
      ],
      "metadata": {
        "id": "FLv1jj_m1Iq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to take means in bins of data\n",
        "def means_in_bins(xs, ys):\n",
        "    nbin = 14\n",
        "    meanx = np.zeros(nbin)\n",
        "    meany = np.zeros(nbin)\n",
        "    stdy = np.zeros(nbin)\n",
        "    for xmin in range(nbin):\n",
        "        I = (xs > xmin) * (xs < (xmin + 1.))\n",
        "        meanx[xmin] = np.mean(xs[I])\n",
        "        meany[xmin] = np.mean(ys[I])\n",
        "        stdy[xmin] = np.std(ys[I]) / np.sqrt(np.sum(I))\n",
        "    return meanx, meany, stdy"
      ],
      "metadata": {
        "id": "K899QqJgxmgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"full data set\")\n",
        "mean_radii, mean_ages, std_ages = means_in_bins(true_guide_radii, ages)\n",
        "plt.scatter(true_guide_radii, ages, s=0.2, c=\"k\", alpha=0.25)\n",
        "plt.plot(mean_radii, mean_ages, \"wo\", mew=4)\n",
        "plt.plot(mean_radii, mean_ages, \"ro\")\n",
        "radiuslim = (0., 14.)\n",
        "plt.xlim(radiuslim)\n",
        "agelim = (0., 15.)\n",
        "plt.ylim(agelim)\n",
        "plt.xlabel(\"guiding radius\")\n",
        "plt.ylabel(\"measured age\")"
      ],
      "metadata": {
        "id": "2gsHpqPxxH3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up train, validate, and test sets\n",
        "X_train = data[:N_train]\n",
        "Y_train = ages[:N_train]\n",
        "X_valid = data[N_train:N_train + N_valid]\n",
        "Y_valid = ages[N_train:N_train + N_valid]\n",
        "X_test = data[N_train + N_valid:]\n",
        "Y_test = ages[N_train + N_valid:]\n",
        "print(X_train.shape, X_valid.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "FVkAizhArP2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"training data (N = {:d})\".format(N_train))\n",
        "radii_train = true_guide_radii[:N_train]\n",
        "mean_train_radii, mean_train_ages, std_train_ages = means_in_bins(radii_train, Y_train)\n",
        "plt.scatter(radii_train, Y_train, s=0.2, c=\"k\", alpha=0.8)\n",
        "shadow_alpha=0.8\n",
        "plt.plot(mean_radii, mean_ages, \"wo\", mew=4, alpha=shadow_alpha)\n",
        "plt.plot(mean_train_radii, mean_train_ages, \"ws\", mfc=\"none\", mew=4, alpha=shadow_alpha)\n",
        "plt.plot(mean_radii, mean_ages, \"ro\", label=\"true relationship\")\n",
        "plt.plot(mean_train_radii, mean_train_ages, \"ks\", mfc=\"none\", label=\"means of training labels in bins\")\n",
        "plt.xlim(radiuslim)\n",
        "plt.ylim(agelim)\n",
        "plt.legend()\n",
        "plt.xlabel(\"guiding radius\")\n",
        "plt.ylabel(\"measured age\")"
      ],
      "metadata": {
        "id": "XsYhsjmZ1SFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up a MLP to solve this problem\n",
        "MLP_kwargs = {'hidden_layer_sizes': (30,30,30),\n",
        "              'activation': 'relu',\n",
        "              'solver': 'adam',\n",
        "              'alpha': 0.0001,\n",
        "              'batch_size': 'auto',\n",
        "              'learning_rate': 'constant',\n",
        "              'learning_rate_init': 0.001,\n",
        "              'power_t': 0.5,\n",
        "              'max_iter': 400,\n",
        "              'shuffle': True,\n",
        "              'random_state': None,\n",
        "              'tol': 0.0001,\n",
        "              'verbose': True,\n",
        "              'warm_start': False,\n",
        "              'momentum': 0.9,\n",
        "              'nesterovs_momentum': True,\n",
        "              'early_stopping': False,\n",
        "              'validation_fraction': 0.1,\n",
        "              'beta_1': 0.9,\n",
        "              'beta_2': 0.999,\n",
        "              'epsilon': 1e-08,\n",
        "              'n_iter_no_change': 10,\n",
        "              'max_fun': 15000}\n",
        "mlp = MLPRegressor(**MLP_kwargs)"
      ],
      "metadata": {
        "id": "xq3XxjuU1VKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform regression\n",
        "regr = mlp.fit(X_train, Y_train)\n",
        "print(regr)"
      ],
      "metadata": {
        "id": "rEAuMrRhPYro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the regression is okay\n",
        "Y_valid_hat = regr.predict(X_valid)\n",
        "print(Y_valid, Y_valid - Y_valid_hat)\n",
        "print(\"bias:\", np.mean(Y_valid - Y_valid_hat))\n",
        "print(\"rms:\", np.sqrt(np.mean((Y_valid - Y_valid_hat) ** 2)))"
      ],
      "metadata": {
        "id": "AFVusvItoPfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"validation set (N = {:d})\".format(N_valid))\n",
        "plt.scatter(Y_valid, Y_valid_hat, s=0.2, c=\"k\")\n",
        "foo = plt.ylim()\n",
        "plt.plot(foo, foo, \"k-\", alpha=0.8, zorder=-10)\n",
        "plt.ylim(agelim)\n",
        "plt.xlim(agelim)\n",
        "plt.xlabel(\"measured age\")\n",
        "plt.ylabel(\"regression-predicted age\")"
      ],
      "metadata": {
        "id": "jcx_Qbiro7w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run on the test set\n",
        "Y_test_hat = regr.predict(X_test)\n",
        "print(Y_test_hat.shape)"
      ],
      "metadata": {
        "id": "nXCsFVtCq6XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"test set (N = {:d})\".format(N_test))\n",
        "radii_test = true_guide_radii[N_train + N_valid:]\n",
        "print(radii_test.shape, Y_test_hat.shape)\n",
        "mean_regr_radii, mean_regr_ages, std_regr_ages = means_in_bins(radii_test, Y_test_hat)\n",
        "nsigma = [\" {:4.1f}\".format(ns) for ns in np.abs(mean_regr_ages - mean_ages) / std_regr_ages]\n",
        "plt.scatter(radii_test, Y_test_hat, s=0.2, c=\"k\", alpha=0.25)\n",
        "i = 12\n",
        "plt.text(mean_regr_radii[i], mean_regr_ages[i], nsigma[i], c=\"w\", fontweight=1000, rotation=45)\n",
        "shadow_alpha=0.8\n",
        "plt.plot(mean_radii, mean_ages, \"wo\", mew=4, alpha=shadow_alpha)\n",
        "plt.plot(mean_train_radii, mean_train_ages, \"ws\", mfc=\"none\", mew=4, alpha=shadow_alpha)\n",
        "plt.plot(mean_regr_radii, mean_regr_ages, \"wx\", mfc=\"none\", mew=4, ms=8, alpha=shadow_alpha)\n",
        "plt.plot(mean_radii, mean_ages, \"ro\", label=\"true relationship\")\n",
        "plt.plot(mean_train_radii, mean_train_ages, \"ks\", mfc=\"none\", label=\"means of training labels in bins\")\n",
        "plt.plot(mean_regr_radii, mean_regr_ages, \"kx\", mfc=\"none\", label=\"means of regression-predicted labels\")\n",
        "plt.xlim(radiuslim)\n",
        "plt.ylim(agelim)\n",
        "plt.legend()\n",
        "plt.xlabel(\"guiding radius\")\n",
        "plt.ylabel(\"regression-predicted age\")"
      ],
      "metadata": {
        "id": "1SpT2UNfsEgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZcOStm5sxOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}