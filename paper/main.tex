% To do:
% ------
% - Write an outline.
% - Fill in the outline.
% - Publish on the arXiv.
% - format for ICML Position Paper and submit.
% - Wait for the call from Stockholm.

% Style notes:
% ------------
% - Uhhh.

\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage[letterpaper]{geometry}

% Hogg typesetting issues
\setlength{\textwidth}{6.50in}
\setlength{\oddsidemargin}{0.00in}
\setlength{\textheight}{9.00in}
\setlength{\topmargin}{-0.50in}
\setlength{\parindent}{1.2\baselineskip} % seriously
\renewenvironment{abstract}{\paragraph{Abstract:}}{}
\renewcommand{\author}[1]{\medskip\par\noindent\textbf{#1}}
\newcommand{\affil}[1]{{\footnotesize\par\noindent #1 \par}}
\linespread{1.08}
\frenchspacing\raggedbottom\sloppy\sloppypar

% Gross
\newcommand{\apj}{The Astrophysical Journal}
\newcommand{\araa}{Annual Reviews in Astronomy and Astrophysics}

% Math issues
\newcommand{\teff}{T_{\mathrm{eff}}}
\newcommand{\logg}{\log g}
\newcommand{\feh}{[\mathrm{Fe}/\mathrm{H}]}

\begin{document}

\section*{Is machine learning good or bad for the natural sciences?}

\author{David W. Hogg}
\affil{Center for Cosmology and Particle Physics, Department of Physics, New York University, 726~Broadway, New~York,~NY 10003, USA}
\affil{Center for Data Science, New York University, 60 Fifth Avenue, New York, NY 10011, USA}
\affil{Max-Planck-Institut f{\"u}r Astronomie, K{\"o}nigstuhl 17, D-69117 Heidelberg, Germany}
\affil{Flatiron Institute, a division of the Simons Foundation, 162 Fifth Avenue, New~York,~NY 10010, USA}

\begin{abstract}
  Machine learning (ML) methods are having a huge impact across all of the sciences.
  However, ML has a strong ontology---in which only the data exist---and a strong epistemology---in which a model is considered good if it performs well on held-out training data.
  These philosophies are in strong conflict with both standard practices and key philosophies in the natural sciences.
  Here we identify locations for ML in the natural sciences where the ontology and epistemology are valuable.
  For example, when a flexible machine-learning model is used in a causal inference to represent the effects of confounders, such as foregrounds, backgrounds, or instrument calibration parameters, the model capacity and loose philosophy of ML can sometimes make the results more trustworthy.
  We also show that the there are contexts in which the introduction of ML introduces strong, unwanted statistical biases.
  For one, when flexible models are used to emulate physical (or first-principles) simulations, they introduce strong confirmation biases.
  For another, when flexible regressions are used to make datasets, the elements of those datasets cannot be used in joint analyses without taking on uncontrolled biases.
  These remarks are intended to apply to all of the natural sciences, but most of the specific examples are in the astrophysics domain.
\end{abstract}

\section{Introduction}\label{sec:intro}

It is an understatement to say that machine learning (ML) is having a big impact across the sciences.
A significant fraction of all scientific papers in the natural sciences now employ ML in part (or all) of their analyses.
However, when we ask what scientific breakthroughs have been enabled by this influx of new tools and methods, there isn't a long list.
The success of the AlphaFold projects in protein structure \cite{alphafold} are often raised.
But these are successes in a very specific challenge-problem setting in which \emph{performance} is valued over \emph{understanding}.
In the natural sciences we almost exclusively care about understanding, in the long run.

The natural sciences are concerned with understanding the world, and naturally occurring mechanisms in play in that world.
We make progress by discovering new kinds of objects and phenomena, and explaining (and, even better, predicting) qualitatively new kinds of objects and phenomena.
Our most successful investigations are judged in terms of the questions they answer, or the new questions they raise, or both.
The question here is: How will ML contribute to this mission?

In contrast to natural science, ML research and ML methods are concerned with making accurate predictions for, or descriptions of, \emph{data}.
A ML method is considered successful if it performs well on held-out training data, even if the latent structure of the model is generic and the internals are impossible to interpret.
In ML, the considerations are all at the level of the data, and we are happy to use models the parameters of which we don't understand in detail.
In natural science, on the other hand, the considerations are all at the level of the \emph{latents}:
We use data to learn about the latent structure of the world or of the system we are studying.
The things we care about are almost never directly observable; they are latent objects in a physical (or chemical or biological) model that predicts the observables.

For a concrete example, when the expansion of the Universe was discovered \cite{expansion, expansion2}, the discovery was important, but not because it permitted us to predict the values of the redshifts of previously unobserved galaxies (though it did indeed permit that).
The discovery was important because it told us previously unknown things about the age and evolution of the Universe, and it confirmed a prediction of general relativity, which is a theory of the latent structure of space and time.
The discovery would not have been seen as important if Hubble and Humason had instead announced that they had trained a deep multilayer perceptron that could predict the Doppler shifts of held-out extragalactic nebulae.

HOGG: NEED to make the point, here or below, that we respect the ML point of view. It could be helpful for some areas in natural science if we moved towards it in some ways. Oh and the statistical care is of interest too. Maybe this should move to the section about the underlying philosophies of ML.

HOGG: Make sure we say: One way to state the question raised in this position paper is:
\emph{Where, in the natural sciences, can you use a model that you don't understand?}

I don't want to sound anti-technological however.
Machine learning is a new and productive technology.
We should use it!
Astrophysics has moved forward through technological progress, starting with Galileo (\cite{galileo}).
In my own lifetime, the most remarkable technological advance was (probably) the change from photographic plates to charge-coupled devices (CCDs; see, for an early review, \cite{ccd}).
In just a few years, almost every telescope and spectrograph in the world switched from a photographic focal plane to a CCD focal plane, and immediately there were new discoveries.
That's a case in which new technology immediately translated into new discoveries.
That hasn't been nearly so true with machine learning, and (I note with respect), it is way easier to incorporate machine learning into your workflow than to incorporate CCDs into your optical path.

I am both a developer of machine-learning methods, and a skeptic who thinks they should only rarely be used.
That said, there are reasons that we absolutely must use machine learning in the near future of astrophysics.
And there are indeed successes of machine learning that might seem invisible.
I'll try to speak to both of these points below.

\paragraph{Our contributions:}
\begin{itemize}
  \item We deliver a description of the fundamental \emph{ontology} and \emph{epistemology} of machine learning, and contrast these with the ontologies and epistemologies of the natural sciences.
  \item We elucidate two important and strong statistical biases that are being introduced to the natural sciences by some of the uses of ML in those disciplines. One is a confirmation bias that arises when simulations are replaced or augmented by emulators. Another is a more standard estimator bias that is (possibly enormously) amplified when elements of datasets produced by ML regressions are used in combination or joint analyses.
  \item We show that there are many safe places for the use of ML methods in current natural-science practices, and places where (in the contemporary context) the use of ML methods is effectively \emph{required}. Many of these places are in the operational parts of scientific projects.
  \item Further, we demonstrate that there are contexts inside a natural-scientific analysis in which using the most flexible ML method delivers \emph{the most conservative approach} to the scientific problem. These contexts are causal contexts, where providing immense flexibility to (say) a confounder model can strengthen conclusions about the causal channels of interest.
\end{itemize}

\section{What is machine learning?}\label{sec:what}

There is a vague definition of machine learning in terms of data and capacity:
A method is a machine-learning method if its capability increases (hopefully dramatically) as the machine sees more data (HOGG GET THIS MORE PRECISE AND CITE).
In some sense this is true of any measurement process:
The measurement improves as more data come in!
So if we are going to be more specific, we'd like the model capacity or capability to improve faster (in some sense) than something like the square root of the increment in data.

There is a more specific definition of machine learning in terms of specific methods:
Whenever a neural network or a Gaussian process is in play, machine learning is in play.
But when the former definition is too broad, the latter is almost always too narrow.
For example, principal components analysis (PCA) is a workhorse in astronomy since way back (for example, \cite{pcaredshift}), and PCA is an old, and simple, but definitely machine-learning, method.

Supervised and unsupervised.

Classification, regression.

Dimensionality reduction, clustering, density estimation.

Something about how we will use the word ``model'' in what follows.

\section{Why do we need machine learning in the natural sciences?}

Label transfer.

Speeding up decisions.

Modeling nuisances.

Classification?

Speeding up simulations?

The short summary is that we need machine learning; we can't live without it.

\section{The ontology and epistemology of machine learning}

HOGG: Definitions of latent variables and so on; what are latent variables and why are they important?

Contemporary machine-learning models---and especially deep-learning models---have explicit unbroken, combinatorically large degeneracies.
That is, the weights and nodes in various layers of the network have permutation symmetries such that a very large space of permutation operators can be applied to the latent space without making any changes whatsoever to the input--output relationships of the model.
That shows that there is no belief in the meaning of any internal latent variables.

Furthermore, stochastic gradient, early stopping and so on:
There isn't even a belief that the latents should be the actual argmin of anything.
The latent values are of absolutely no importance or meaning whatsoever.

If there is any stability to a model, it is the stability of its predictions, or its behavior on held-out data.

Also maybe mention here the statistical philosophy or care.

\section{When is machine learning a bad idea?}

Adversarial attacks argument. Confirmation bias argument. Planet search argument.

\section{When is machine learning the conservative choice?}

Come back to the planet-search example.

\section{Discussion}\label{sec:discussion}

Hello World!

\paragraph{Acknowledgements:}
Hill, Roweis, Sch\"olkopf, Villar.

\bibliography{ml_in_astro}
\bibliographystyle{plain}

\end{document}
